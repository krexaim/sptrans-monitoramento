# SPTrans - Monitoramento

## Objetivo
Este projeto tem como objetivo desenvolver um pipeline de dados completo para o monitoramento do transporte p√∫blico da cidade de S√£o Paulo, utilizando a API Olho Vivo da SPTrans.
O pipeline realiza a ingest√£o, transforma√ß√£o e disponibiliza√ß√£o dos dados, orquestrado pelo Apache Airflow, com armazenamento no MinIO e processamento via PySpark. Os dados brutos s√£o armazenados em camadas Bronze (JSON) e transformados em Silver e Gold (Delta) para posterior an√°lise e consumo via DuckDB e Metabase.

O sistema coleta informa√ß√µes de posi√ß√£o dos √¥nibus a cada 2 minutos (batch), e os dados transformados alimentam um dashboard interativo, que exibir√° informa√ß√µes em near real-time e KPIs operacionais do sistema de transporte.

O projeto tem foco em aprendizado e portf√≥lio, aplicando boas pr√°ticas de engenharia de dados e arquitetura de pipelines escal√°veis.

## Arquitetura de Solu√ß√£o

![Arquitetura do Projeto](docs/images/Arquitetura.png)

## Stack de Tecnologias

| Componente          | Fun√ß√£o                      | Tecnologia                          |
| ------------------- | --------------------------- | ----------------------------------- |
| üß© Orquestra√ß√£o     | Agendamento e monitoramento | **Apache Airflow 2.10** + Postgres 15 backend |
| ‚ö° Processamento     | ETL e transforma√ß√µes        | **Apache Spark 3.5.3 + Delta Lake 3.3.2** |
| ü™£ Armazenamento    | Data Lake compat√≠vel com S3 | **MinIO**                           |
| üóÑÔ∏è Banco anal√≠tico | Consultas r√°pidas e locais, alimenta o Metabase  | **DuckDB**                          |
| üìä Visualiza√ß√£o     | Dashboards e KPIs           | **Metabase**                        |
| üêç Linguagem        | Ingest√£o e integra√ß√£o       | **Python 3**                     |
| üõ∞Ô∏è Fonte de dados  | API em tempo real e GTFS    | **SPTrans Olho Vivo + GTFS**        |


Docker - containeriza√ß√£o e ambiente padronizado para todos os servi√ßos

## Camadas de Dados do Data Lake (Medalh√£o)

| Camada        | Formato | Descri√ß√£o                                        |
| ------------- | ------- | ------------------------------------------------ |
| ü•â **Bronze** | JSON e TXT(CSV)   | Dados brutos extra√≠dos da API SPTrans e arquivos est√°ticos do GTFS da SPTrans   |
| ü•à **Silver** | Delta   | Dados tratados, normalizados e particionados.    |
| ü•á **Gold**   | Delta   | Dados anal√≠ticos prontos para KPIs e dashboards. |

## Pipelines e DAGs

1. Ingest√£o (Bronze)
   1. ```ingest_linhas_paradas.py``` -  1x/dia
     * Baixa dados de linhas e paradas via API.
     * Salva em ```s3a://bronze/linhas/``` e ```s3a://bronze/paradas/``` particionado por ano/m√™s/dia.
   2. ```ingest_transform_posicao.py``` - 1x/2 minutos
     * Captura informa√ß√µes sobre posi√ß√£o de √¥nibus em near real-time.
     * Salva em ```s3a://bronze/posicao/``` particionado por ano/m√™s/dia.
   3. Upload manual do [GTFS SPTrans](https://www.sptrans.com.br/desenvolvedores/) para ```s3a://bronze/gtfs/``` 1x/semana
2.  Transforma√ß√£o (Silver)
    1.  ```transform_linhas_bronze_silver.py``` - Cria Delta table de linhas.
    2.  ```transform_paradas_bronze_silver.py```- Cria Delta table de paradas.
    3.  ```transform_gtfs_bronze_silver.py``` - Processa os arquivos GTFS (`routes`, `stops`, `trips`, `stop_times`, `shapes`).
    4.  ```transform_posicao_bronze_silver.py```- Cria Delta Table incremental de posi√ß√µes (merge(upsert) por `codigo_veiculo` e `hora_referencia`)
3.  Camada Gold (Anal√≠tica)
    1.  ```transform_gold_dim_linha.py``` - Junta Silver/linhas com GTFS/routes para criar dimens√£o de linha.
    2.  ```transform_gold_dim_parada.py``` - Enriquece paradas da API com dados est√°ticos do `GTFS/stops` para criar a dimens√£o de parada.
    3.  ```transform_gold_fato_posicao.py``` - Mant√©m apenas os dados fatos da posi√ß√£o de √¥nibus, integrando posi√ß√£o da silver e `codigo_linha`.
   
## Dashboard
![Dashboard](docs/images/dashboard.png)

<!-- ##### Pr√©-requisitos
- [Docker e Docker Compose](https://docs.docker.com/compose/install/) instalados.
- [Chave de acesso da API Olho Vivo da SPTrans.](https://www.sptrans.com.br/desenvolvedores/api-do-olho-vivo-guia-de-referencia/)

##### Configura√ß√£o
1. Clonar o reposit√≥rio:
```
git clone https://github.com/krexaim/sptrans-monitoramento.git
cd sptrans-monitoramento
```
2. Criar um arquivo .env, copiar/colar os seguintes dados no .env e inserir o seu token da API
```
#SPTRANS
SPTRANS_API_KEY= seu token aqui

# MINIO
MINIO_ENDPOINT_LOCAL=localhost:9000
MINIO_ENDPOINT_DOCKER=minio:9000
MINIO_ROOT_USER=admin
MINIO_ROOT_PASSWORD=minioadmin
```
##### Subindo o ambiente
```
docker compose up -d
```
##### Acessando os dados
| Servi√ßo | Usu√°rio | Senha | 
|---|---|---|
| [Airflow](http://localhost:8080/) | admin | admin |
| [MinIO](http://localhost:9001/login) | admin | minioadmin |
| [Spark Master UI](http://localhost:8081) | n/a | n/a|
| [Metabase](http:O//localhost:3000)| criar | criar | -->

## Autores

<p align="center">
  <table>
    <tr>
      <td align="center" width="50%">
        <strong>Alex Kim</strong><br>
         <a href="https://www.linkedin.com/in/alex-kim-97b97910b/" target="_blank">LinkedIn</a>  
        |  <a href="https://github.com/krexaim" target="_blank">GitHub</a>
      </td>
      <td align="center" width="50%">
        <strong>√çtalo Berioni</strong><br>
         <a href="https://www.linkedin.com/in/italoberioni/" target="_blank">LinkedIn</a>  
        |  <a href="https://github.com/Beriond" target="_blank">GitHub</a>
      </td>
    </tr>
  </table>
</p>