{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d8059eb-7884-4dea-a5e9-356cf8e7d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo Bronze de: s3a://bronze/linhas/2025/11/07/\n",
      "Gravando Silver em: s3a://silver/dim_linhas/\n"
     ]
    }
   ],
   "source": [
    "# LINHAS: Bronze -> Silver (Parquet, sem Delta)\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, explode, current_timestamp, to_date, lit\n",
    "\n",
    "# --- Paths ---\n",
    "today = datetime.now().strftime(\"%Y/%m/%d\")\n",
    "BRONZE_PATH = f\"s3a://bronze/linhas/{today}/\"   # ajuste se seu prefixo for outro (ex.: linhas_ref)\n",
    "SILVER_PATH = \"s3a://silver/dim_linhas/\"\n",
    "\n",
    "print(f\"Lendo Bronze de: {BRONZE_PATH}\")\n",
    "print(f\"Gravando Silver em: {SILVER_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1b06c37-a65b-4e9b-a283-2bf7e3a71a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SparkSession (S3A/MinIO) ---\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"BronzeToSilver_Linhas_Parquet\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"admin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", True)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70483379-9c48-4484-bfa0-9147b0d050a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Schema do JSON de linhas (array na raiz) ---\n",
    "schema_item = StructType([\n",
    "    StructField(\"cl\", IntegerType(), True),   # código interno da linha\n",
    "    StructField(\"lc\", BooleanType(), True),\n",
    "    StructField(\"lt\", StringType(), True),    # código visível (ex.: \"1012\")\n",
    "    StructField(\"sl\", IntegerType(), True),   # sentido\n",
    "    StructField(\"tl\", IntegerType(), True),   # tipo linha (qdo existir)\n",
    "    StructField(\"tp\", StringType(), True),    # terminal origem\n",
    "    StructField(\"ts\", StringType(), True),    # terminal destino\n",
    "])\n",
    "schema_array = ArrayType(schema_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b49909-e32f-464f-b4c2-f49d13f27e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Leitura robusta (array na raiz) ---\n",
    "raw = (spark.sparkContext\n",
    "       .wholeTextFiles(f\"{BRONZE_PATH.rstrip('/')}\" + \"/*.json\")\n",
    "       .toDF([\"path\",\"raw\"]))\n",
    "ddl = \"array<struct<cl:int, lc:boolean, lt:string, sl:int, tl:int, tp:string, ts:string>>\"\n",
    "df_arr = raw.selectExpr(\n",
    "    \"path\",\n",
    "    f\"from_json(raw, '{ddl}') as arr\"\n",
    "    )\n",
    "df_lin = df_arr.select(\"path\", explode(col(\"arr\")).alias(\"r\"))\n",
    "\n",
    "# --- Limpeza/seleção (snapshot do dia) ---\n",
    "df_clean = (\n",
    "    df_lin\n",
    "    .select(\n",
    "        col(\"r.cl\").alias(\"line_id\"),\n",
    "        col(\"r.lt\").alias(\"line_code\"),\n",
    "        col(\"r.sl\").alias(\"sentido\"),\n",
    "        col(\"r.tl\").alias(\"tipo_linha\"),\n",
    "        col(\"r.tp\").alias(\"terminal_origem\"),\n",
    "        col(\"r.ts\").alias(\"terminal_destino\"),\n",
    "    )\n",
    "    .dropDuplicates([\"line_id\", \"line_code\", \"sentido\"])       # evita duplicatas do mesmo snapshot\n",
    "    .withColumn(\"dt\", to_date(current_timestamp()))            # partição de snapshot diário\n",
    "    .withColumn(\"ingest_ts\", current_timestamp())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40fcdbea-3cc6-4752-9244-0cfc919e0e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Linhas: transformação concluída e salva em Parquet na camada Silver.\n"
     ]
    }
   ],
   "source": [
    "# --- Escrita em Parquet (snapshot diário) ---\n",
    "# Para snapshot do dia, normalmente usamos overwrite NA PARTIÇÃO do dia.\n",
    "# Se preferir append puro, troque para .mode(\"append\").\n",
    "(\n",
    "    df_clean\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"dt\")\n",
    "    .parquet(SILVER_PATH)\n",
    ")\n",
    "\n",
    "print(\"✅ Linhas: transformação concluída e salva em Parquet na camada Silver.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ab2f41-d591-4d0e-9d30-c7eb68aeed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-------+----------+-------------------+----------------+-------------------------+----------+\n",
      "|line_id|line_code|sentido|tipo_linha|terminal_origem    |terminal_destino|ingest_ts                |dt        |\n",
      "+-------+---------+-------+----------+-------------------+----------------+-------------------------+----------+\n",
      "|1      |5119     |1      |10        |LGO. SÃO FRANCISCO |TERM. CAPELINHA |2025-11-07 03:44:49.77775|2025-11-07|\n",
      "|4      |669A     |1      |10        |TERM. PRINC. ISABEL|TERM. STO. AMARO|2025-11-07 03:44:49.77775|2025-11-07|\n",
      "|5      |6801     |1      |10        |TERM. JOÃO DIAS    |JD. IBIRAPUERA  |2025-11-07 03:44:49.77775|2025-11-07|\n",
      "|6      |6837     |1      |10        |TERM. CAPELINHA    |SHOP. PORTAL    |2025-11-07 03:44:49.77775|2025-11-07|\n",
      "|8      |695V     |1      |10        |METRÔ ANA ROSA     |TERM. CAPELINHA |2025-11-07 03:44:49.77775|2025-11-07|\n",
      "|12     |6835     |1      |10        |TERM. CAPELINHA    |VALO VELHO      |2025-11-07 03:44:49.77775|2025-11-07|\n",
      "|13     |6836     |1      |10        |TERM. JOÃO DIAS    |CAPÃO REDONDO   |2025-11-07 03:44:49.77775|2025-11-07|\n",
      "|14     |6825     |1      |10        |TERM. CAPELINHA    |VALO VELHO      |2025-11-07 03:44:49.77775|2025-11-07|\n",
      "|16     |6826     |1      |10        |TERM. CAPELINHA    |JD. D. JOSÉ     |2025-11-07 03:44:49.77775|2025-11-07|\n",
      "|19     |6820     |1      |10        |TERM. CAPELINHA    |JD. DAS ROSAS   |2025-11-07 03:44:49.77775|2025-11-07|\n",
      "+-------+---------+-------+----------+-------------------+----------------+-------------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Validação rápida ---\n",
    "df_result = spark.read.parquet(SILVER_PATH)\n",
    "df_result.orderBy(col(\"dt\").desc(), col(\"line_id\")).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e8cbf-8bda-44d1-b4ff-5283734f8588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
