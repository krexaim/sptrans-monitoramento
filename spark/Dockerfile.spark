# -------------------------------------------------------------------
# Dockerfile.spark ‚Äî Spark Standalone with PySpark + MinIO Connector 
# Base: Eclipse Temurin (OpenJDK 11)
# -------------------------------------------------------------------
FROM eclipse-temurin:11-jdk-jammy

# -----------------------------
# 1Ô∏è‚É£ Instalar depend√™ncias
# -----------------------------
RUN apt-get update && apt-get install -y \
    curl python3 python3-pip wget && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

# -----------------------------
# 2Ô∏è‚É£ Instalar PySpark, findspark, delta
# -----------------------------
RUN pip3 install pyspark==3.5.3 findspark delta-spark

# -----------------------------
# 3Ô∏è‚É£ Baixar e configurar Apache Spark
# -----------------------------
COPY spark-3.5.3-bin-hadoop3.tgz /tmp/
RUN tar xvf /tmp/spark-3.5.3-bin-hadoop3.tgz && \
    mv spark-3.5.3-bin-hadoop3 /opt/spark && \
    rm /tmp/spark-3.5.3-bin-hadoop3.tgz

# -----------------------------
# 4Ô∏è‚É£ Vari√°veis de ambiente
# -----------------------------
ENV SPARK_HOME=/opt/spark
ENV PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
ENV PYSPARK_PYTHON=python3
ENV PYTHONPATH=$SPARK_HOME/python/:$PYTHONPATH

# -----------------------------
# 5Ô∏è‚É£ Adicionar conectores Hadoop S3A (MinIO) + Delta Lake
# -----------------------------
RUN wget https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar -P $SPARK_HOME/jars/ && \
    wget https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar -P $SPARK_HOME/jars/ && \
    wget https://repo1.maven.org/maven2/io/delta/delta-core_2.12/2.4.0/delta-core_2.12-2.4.0.jar -P $SPARK_HOME/jars/

# -----------------------------
# 6Ô∏è‚É£ Configurar Spark Master UI
# -----------------------------
ENV SPARK_MASTER_HOST=0.0.0.0
ENV SPARK_MASTER_PORT=7077
ENV SPARK_MASTER_WEBUI_PORT=8080
COPY spark-defaults.conf ${SPARK_HOME}/conf/spark-defaults.conf

# -----------------------------
# 7Ô∏è‚É£ Diret√≥rio de trabalho
# -----------------------------
WORKDIR /opt/workspace

# -----------------------------
# 8Ô∏è‚É£ Expor portas para acesso
# -----------------------------
EXPOSE 7077 8080 4040

# -----------------------------
# 9Ô∏è‚É£ Comando padr√£o (Master)
# -----------------------------
CMD if [ "$SPARK_MODE" = "worker" ]; then \
      echo "üîß Starting Spark Worker, connecting to $SPARK_MASTER..."; \
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker "$SPARK_MASTER"; \
    else \
      echo "üöÄ Starting Spark Master..."; \
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master \
        --host 0.0.0.0 --port 7077 --webui-port 8080; \
    fi